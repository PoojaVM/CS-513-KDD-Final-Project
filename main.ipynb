{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course - CS-513 Knowledge Discovery and Data Mining\n",
    "#### Problem Statement - Predict the prices of real estate in New York City using the dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84548 entries, 0 to 84547\n",
      "Data columns (total 22 columns):\n",
      " #   Column                          Non-Null Count  Dtype \n",
      "---  ------                          --------------  ----- \n",
      " 0   Unnamed: 0                      84548 non-null  int64 \n",
      " 1   BOROUGH                         84548 non-null  int64 \n",
      " 2   NEIGHBORHOOD                    84548 non-null  object\n",
      " 3   BUILDING CLASS CATEGORY         84548 non-null  object\n",
      " 4   TAX CLASS AT PRESENT            84548 non-null  object\n",
      " 5   BLOCK                           84548 non-null  int64 \n",
      " 6   LOT                             84548 non-null  int64 \n",
      " 7   EASE-MENT                       84548 non-null  object\n",
      " 8   BUILDING CLASS AT PRESENT       84548 non-null  object\n",
      " 9   ADDRESS                         84548 non-null  object\n",
      " 10  APARTMENT NUMBER                84548 non-null  object\n",
      " 11  ZIP CODE                        84548 non-null  int64 \n",
      " 12  RESIDENTIAL UNITS               84548 non-null  int64 \n",
      " 13  COMMERCIAL UNITS                84548 non-null  int64 \n",
      " 14  TOTAL UNITS                     84548 non-null  int64 \n",
      " 15  LAND SQUARE FEET                84548 non-null  object\n",
      " 16  GROSS SQUARE FEET               84548 non-null  object\n",
      " 17  YEAR BUILT                      84548 non-null  int64 \n",
      " 18  TAX CLASS AT TIME OF SALE       84548 non-null  int64 \n",
      " 19  BUILDING CLASS AT TIME OF SALE  84548 non-null  object\n",
      " 20  SALE PRICE                      84548 non-null  object\n",
      " 21  SALE DATE                       84548 non-null  object\n",
      "dtypes: int64(10), object(12)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('nyc-rolling-sales.csv')\n",
    "\n",
    "# Dataset columns pre-cleanup\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84548 entries, 0 to 84547\n",
      "Data columns (total 18 columns):\n",
      " #   Column                          Non-Null Count  Dtype \n",
      "---  ------                          --------------  ----- \n",
      " 0   BOROUGH                         84548 non-null  int64 \n",
      " 1   NEIGHBORHOOD                    84548 non-null  object\n",
      " 2   BUILDING CLASS CATEGORY         84548 non-null  object\n",
      " 3   TAX CLASS AT PRESENT            83810 non-null  object\n",
      " 4   BLOCK                           84548 non-null  int64 \n",
      " 5   BUILDING CLASS AT PRESENT       83810 non-null  object\n",
      " 6   APARTMENT NUMBER                19052 non-null  object\n",
      " 7   ZIP CODE                        84548 non-null  int64 \n",
      " 8   RESIDENTIAL UNITS               84548 non-null  int64 \n",
      " 9   COMMERCIAL UNITS                84548 non-null  int64 \n",
      " 10  TOTAL UNITS                     84548 non-null  int64 \n",
      " 11  LAND SQUARE FEET                58296 non-null  object\n",
      " 12  GROSS SQUARE FEET               56936 non-null  object\n",
      " 13  YEAR BUILT                      84548 non-null  int64 \n",
      " 14  TAX CLASS AT TIME OF SALE       84548 non-null  int64 \n",
      " 15  BUILDING CLASS AT TIME OF SALE  84548 non-null  object\n",
      " 16  SALE PRICE                      69987 non-null  object\n",
      " 17  SALE DATE                       84548 non-null  object\n",
      "dtypes: int64(8), object(10)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Clean dataset\n",
    "\n",
    "# Drop Unnamed: 0 feature which is just a serial number\n",
    "# Drop ADDRESS and LOT features as it is not required for analysis.\n",
    "df.drop([\"ADDRESS\", \"Unnamed: 0\", \"LOT\"], axis=1, inplace=True)\n",
    "\n",
    "# Check and drop columns where all cells are empty or -\n",
    "df = df.applymap(lambda x: pd.NA if str(x).strip() in ['-', ''] else x)\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Dataset columns post-cleanup\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Rows, Columns): (84548, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>NEIGHBORHOOD</th>\n",
       "      <th>BUILDING CLASS CATEGORY</th>\n",
       "      <th>TAX CLASS AT PRESENT</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>BUILDING CLASS AT PRESENT</th>\n",
       "      <th>APARTMENT NUMBER</th>\n",
       "      <th>ZIP CODE</th>\n",
       "      <th>RESIDENTIAL UNITS</th>\n",
       "      <th>COMMERCIAL UNITS</th>\n",
       "      <th>TOTAL UNITS</th>\n",
       "      <th>LAND SQUARE FEET</th>\n",
       "      <th>GROSS SQUARE FEET</th>\n",
       "      <th>YEAR BUILT</th>\n",
       "      <th>TAX CLASS AT TIME OF SALE</th>\n",
       "      <th>BUILDING CLASS AT TIME OF SALE</th>\n",
       "      <th>SALE PRICE</th>\n",
       "      <th>SALE DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2A</td>\n",
       "      <td>392</td>\n",
       "      <td>C2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10009</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1633</td>\n",
       "      <td>6440</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C2</td>\n",
       "      <td>6625000</td>\n",
       "      <td>2017-07-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "      <td>C7</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10009</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>4616</td>\n",
       "      <td>18690</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C7</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2016-12-14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "      <td>C7</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10009</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2212</td>\n",
       "      <td>7803</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C7</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2016-12-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2B</td>\n",
       "      <td>402</td>\n",
       "      <td>C4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10009</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2272</td>\n",
       "      <td>6794</td>\n",
       "      <td>1913</td>\n",
       "      <td>2</td>\n",
       "      <td>C4</td>\n",
       "      <td>3936272</td>\n",
       "      <td>2016-09-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2A</td>\n",
       "      <td>404</td>\n",
       "      <td>C2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10009</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2369</td>\n",
       "      <td>4615</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C2</td>\n",
       "      <td>8000000</td>\n",
       "      <td>2016-11-17 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BOROUGH   NEIGHBORHOOD                      BUILDING CLASS CATEGORY  \\\n",
       "0        1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n",
       "1        1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n",
       "2        1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n",
       "3        1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n",
       "4        1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n",
       "\n",
       "  TAX CLASS AT PRESENT  BLOCK BUILDING CLASS AT PRESENT APARTMENT NUMBER  \\\n",
       "0                   2A    392                        C2             <NA>   \n",
       "1                    2    399                        C7             <NA>   \n",
       "2                    2    399                        C7             <NA>   \n",
       "3                   2B    402                        C4             <NA>   \n",
       "4                   2A    404                        C2             <NA>   \n",
       "\n",
       "   ZIP CODE  RESIDENTIAL UNITS  COMMERCIAL UNITS  TOTAL UNITS  \\\n",
       "0     10009                  5                 0            5   \n",
       "1     10009                 28                 3           31   \n",
       "2     10009                 16                 1           17   \n",
       "3     10009                 10                 0           10   \n",
       "4     10009                  6                 0            6   \n",
       "\n",
       "  LAND SQUARE FEET GROSS SQUARE FEET  YEAR BUILT  TAX CLASS AT TIME OF SALE  \\\n",
       "0             1633              6440        1900                          2   \n",
       "1             4616             18690        1900                          2   \n",
       "2             2212              7803        1900                          2   \n",
       "3             2272              6794        1913                          2   \n",
       "4             2369              4615        1900                          2   \n",
       "\n",
       "  BUILDING CLASS AT TIME OF SALE SALE PRICE            SALE DATE  \n",
       "0                             C2    6625000  2017-07-19 00:00:00  \n",
       "1                             C7       <NA>  2016-12-14 00:00:00  \n",
       "2                             C7       <NA>  2016-12-09 00:00:00  \n",
       "3                             C4    3936272  2016-09-23 00:00:00  \n",
       "4                             C2    8000000  2016-11-17 00:00:00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View dataset statistics\n",
    "\n",
    "print('(Rows, Columns):', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with total units != commercial units + residential units: 0\n",
      "\n",
      "\n",
      "Data type of features BOROUGH                            int64\n",
      "NEIGHBORHOOD                      object\n",
      "BUILDING CLASS CATEGORY           object\n",
      "TAX CLASS AT PRESENT              object\n",
      "BLOCK                              int64\n",
      "BUILDING CLASS AT PRESENT         object\n",
      "APARTMENT NUMBER                  object\n",
      "ZIP CODE                           int64\n",
      "RESIDENTIAL UNITS                  int64\n",
      "COMMERCIAL UNITS                   int64\n",
      "TOTAL UNITS                        int64\n",
      "LAND SQUARE FEET                  object\n",
      "GROSS SQUARE FEET                 object\n",
      "YEAR BUILT                         int64\n",
      "TAX CLASS AT TIME OF SALE          int64\n",
      "BUILDING CLASS AT TIME OF SALE    object\n",
      "SALE PRICE                        object\n",
      "SALE DATE                         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with total units is not equal to commercial units + residential units\n",
    "df = df[df[\"TOTAL UNITS\"] == (df[\"COMMERCIAL UNITS\"] + df[\"RESIDENTIAL UNITS\"])]\n",
    "\n",
    "print(\n",
    "    \"Rows with total units != commercial units + residential units:\",\n",
    "    df[df[\"TOTAL UNITS\"] != df[\"COMMERCIAL UNITS\"] + df[\"RESIDENTIAL UNITS\"]].shape[0],\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check data type of features\n",
    "print(\"Data type of features\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns:\n",
      "['BOROUGH', 'NEIGHBORHOOD', 'BUILDING CLASS CATEGORY', 'TAX CLASS AT PRESENT', 'BUILDING CLASS AT PRESENT', 'APARTMENT NUMBER', 'LAND SQUARE FEET', 'GROSS SQUARE FEET', 'TAX CLASS AT TIME OF SALE', 'BUILDING CLASS AT TIME OF SALE', 'SALE PRICE', 'SALE DATE'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find categorical columns - columns with less than 10 unique values considered cateogrical for the purpose\n",
    "\n",
    "categorical_columns = []\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object' or df[column].nunique() < 10:\n",
    "        categorical_columns.append(column)\n",
    "\n",
    "\n",
    "print('Categorical columns:')\n",
    "print(categorical_columns, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out categorical features from 'categorical_columns' if they are truly useful in categorical sense\n",
    "categorical_columns = [\n",
    "    'BOROUGH',\n",
    "    'NEIGHBORHOOD',\n",
    "    'TAX CLASS AT PRESENT',\n",
    "    'BUILDING CLASS CATEGORY',\n",
    "    'BUILDING CLASS AT PRESENT',\n",
    "    'TAX CLASS AT TIME OF SALE',\n",
    "    'BUILDING CLASS AT TIME OF SALE',\n",
    "]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    # Convert to categorical data type\n",
    "    df[col] = df[col].astype('category')\n",
    "    # Do label encoding\n",
    "    df[col] = df[col].cat.codes\n",
    "\n",
    "# Convert other feature data types to numeric wherever suitable\n",
    "df['SALE PRICE'] = pd.to_numeric(df['SALE PRICE'])\n",
    "df['LAND SQUARE FEET'] = pd.to_numeric(df['LAND SQUARE FEET'], errors='coerce')\n",
    "df['GROSS SQUARE FEET']= pd.to_numeric(df['GROSS SQUARE FEET'], errors='coerce')\n",
    "\n",
    "# Convert SALE DATE to datetime and extact year\n",
    "df['SALE DATE'] = pd.to_datetime(df['SALE DATE'], errors='coerce')\n",
    "# df['SALE YEAR'] = df['SALE DATE'].dt.year\n",
    "df[\"SALE DATE\"] = pd.DatetimeIndex(df[\"SALE DATE\"]).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of features:\n"
     ]
    }
   ],
   "source": [
    "# Check if all features are appropriately set as per thier data types\n",
    "print(\"Data type of features:\")\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot histogram for numerical data\n",
    "# for column in df.columns:\n",
    "#     # Check if the column is numeric\n",
    "#     if pd.api.types.is_numeric_dtype(df[column]):\n",
    "#         # Plot a histogram for numeric data\n",
    "#         plt.figure(figsize=(8, 4))\n",
    "#         sns.histplot(df[column], kde=True)\n",
    "#         plt.title(f\"Histogram of {column}\")\n",
    "#         plt.xlabel(column)\n",
    "#         plt.ylabel(\"Frequency\")\n",
    "#         plt.show()\n",
    "\n",
    "    # # Check if the column is categorical\n",
    "    # elif pd.api.types.is_categorical_dtype(df[column]):\n",
    "    #     # Plot a countplot for categorical data\n",
    "    #     plt.figure(figsize=(8, 4))\n",
    "    #     sns.countplot(x=column, data=df)\n",
    "    #     plt.title(f'Countplot of {column}')\n",
    "    #     plt.xlabel(column)\n",
    "    #     plt.ylabel('Count')\n",
    "    #     plt.xticks(rotation=45)\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Missing data - understand percentage of missing data\n",
    "\n",
    "\n",
    "def show_missing_values(dataframe):\n",
    "    # Calculate the percentage of missing data in each column\n",
    "    missing_percentage = dataframe.isnull().mean() * 100\n",
    "\n",
    "    # Create a bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    missing_percentage.plot(kind=\"bar\")\n",
    "    plt.ylabel(\"Percentage of Missing Data\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.title(\"Percentage of Missing Data by Feature\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "show_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n",
    "\n",
    "# get nunique values of zip code\n",
    "df['ZIP CODE'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null or 0 values after cleanup from SALE PRICE: 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58960 entries, 0 to 84547\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   BOROUGH                         58960 non-null  int8   \n",
      " 1   NEIGHBORHOOD                    58960 non-null  int16  \n",
      " 2   BUILDING CLASS CATEGORY         58960 non-null  int8   \n",
      " 3   TAX CLASS AT PRESENT            58960 non-null  int8   \n",
      " 4   BLOCK                           58960 non-null  int64  \n",
      " 5   BUILDING CLASS AT PRESENT       58960 non-null  int16  \n",
      " 6   ZIP CODE                        58960 non-null  int64  \n",
      " 7   RESIDENTIAL UNITS               58960 non-null  int64  \n",
      " 8   COMMERCIAL UNITS                58960 non-null  int64  \n",
      " 9   TOTAL UNITS                     58960 non-null  int64  \n",
      " 10  LAND SQUARE FEET                38270 non-null  float64\n",
      " 11  GROSS SQUARE FEET               37719 non-null  float64\n",
      " 12  YEAR BUILT                      58960 non-null  int64  \n",
      " 13  TAX CLASS AT TIME OF SALE       58960 non-null  int8   \n",
      " 14  BUILDING CLASS AT TIME OF SALE  58960 non-null  int16  \n",
      " 15  SALE PRICE                      58960 non-null  float64\n",
      " 16  SALE DATE                       58960 non-null  int64  \n",
      "dtypes: float64(3), int16(3), int64(7), int8(4)\n",
      "memory usage: 5.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.0        742\n",
       "450000.0    426\n",
       "550000.0    414\n",
       "650000.0    413\n",
       "600000.0    407\n",
       "           ... \n",
       "313627.0      1\n",
       "347295.0      1\n",
       "371500.0      1\n",
       "458784.0      1\n",
       "69300.0       1\n",
       "Name: SALE PRICE, Length: 9742, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treating missing values\n",
    "\n",
    "# Cateogorical values for SALE PRICE\n",
    "SALE_PRICE_LABELS = [\"Low\", \"Medium\", \"High\", \"Very High\"]\n",
    "\n",
    "# Remove rows with missing or 0 values in SALE PRICE which is target variable\n",
    "df[\"SALE PRICE\"] = df[\"SALE PRICE\"].apply(lambda x: np.NAN if x <= 0 or \"\" else x)\n",
    "df.dropna(subset=[\"SALE PRICE\"], inplace=True)\n",
    "\n",
    "# Check if SALE PRICE has any NA values\n",
    "print(\n",
    "    \"Number of null or 0 values after cleanup from SALE PRICE:\",\n",
    "    df[\"SALE PRICE\"].isna().sum(),\n",
    ")\n",
    "\n",
    "\n",
    "# Delete the APARTMENT NUMBER since 77% of the values are missing and it is not a useful feature\n",
    "df.drop(\"APARTMENT NUMBER\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Remove rows with missing values in TAX CLASS AT PRESENT and BUILDING CLASS AT PRESENT\n",
    "df.dropna(subset=[\"TAX CLASS AT PRESENT\", \"BUILDING CLASS AT PRESENT\"], inplace=True)\n",
    "\n",
    "# Do k-means clustering to remove outliers from all numeric features\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def kmeans_remove_outliers(df, n_clusters=5, random_state=0):\n",
    "    # Standardize selected features\n",
    "    scaler = StandardScaler()\n",
    "    standardized_features = scaler.fit_transform(df)\n",
    "    # Perform k-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state).fit(standardized_features)\n",
    "    # Calculate distances of each data point from the cluster centers\n",
    "    distances = kmeans.transform(standardized_features)\n",
    "    # Find closest cluster for each data point\n",
    "    closest_cluster_distances = np.min(distances, axis=1)\n",
    "    # Determine the threshold value for outliers\n",
    "    threshold_distance = np.mean(closest_cluster_distances) + 3 * np.std(closest_cluster_distances)\n",
    "    # Flag the outliers\n",
    "    outliers = closest_cluster_distances > threshold_distance\n",
    "    # Remove the outliers\n",
    "    df = df[~outliers]\n",
    "    # Change SALE PRICE to categorical variable\n",
    "    df[\"SALE PRICE\"] = pd.qcut(df[\"SALE PRICE\"], q=4, labels=SALE_PRICE_LABELS)\n",
    "    return df\n",
    "\n",
    "\n",
    "df[\"SALE PRICE\"].describe()\n",
    "\n",
    "# change SALE PRICE to categorical variable\n",
    "# SALE_PRICE_LABELS = [\"Low\", \"Medium\", \"High\", \"Very High\"]\n",
    "# df[\"SALE PRICE\"] = pd.qcut(df[\"SALE PRICE\"], q=4, labels=SALE_PRICE_LABELS)\n",
    "\n",
    "df.info()\n",
    "\n",
    "df[\"SALE PRICE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if LAND SQUARE FEET and GROSS SQUARE FEET are normally distributed\n",
    "\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# sns.histplot(df['LAND SQUARE FEET'], kde=True)\n",
    "# plt.title('Histogram of LAND SQUARE FEET')\n",
    "# plt.xlabel('LAND SQUARE FEET')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# sns.histplot(df['GROSS SQUARE FEET'], kde=True)\n",
    "# plt.title('Histogram of GROSS SQUARE FEET')\n",
    "# plt.xlabel('GROSS SQUARE FEET')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/jnqxrkbx5_x2fyjcbdhqfr3h0000gn/T/ipykernel_91896/3642752013.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"SALE PRICE\"] = pd.qcut(df[\"SALE PRICE\"], q=4, labels=SALE_PRICE_LABELS)\n",
      "/var/folders/dv/jnqxrkbx5_x2fyjcbdhqfr3h0000gn/T/ipykernel_91896/3642752013.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"SALE PRICE\"] = pd.qcut(df[\"SALE PRICE\"], q=4, labels=SALE_PRICE_LABELS)\n",
      "/var/folders/dv/jnqxrkbx5_x2fyjcbdhqfr3h0000gn/T/ipykernel_91896/3642752013.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"SALE PRICE\"] = pd.qcut(df[\"SALE PRICE\"], q=4, labels=SALE_PRICE_LABELS)\n",
      "/var/folders/dv/jnqxrkbx5_x2fyjcbdhqfr3h0000gn/T/ipykernel_91896/3642752013.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"SALE PRICE\"] = pd.qcut(df[\"SALE PRICE\"], q=4, labels=SALE_PRICE_LABELS)\n"
     ]
    }
   ],
   "source": [
    "# Create duplicate df for imputation\n",
    "df_median_impute = df.copy()\n",
    "df_mean_inpute = df.copy()\n",
    "df_knn_impute = df.copy()\n",
    "df_no_impute = df.copy()\n",
    "\n",
    "# Impute the missing values in LAND SQUARE FEET and GROSS SQUARE FEET using different methods\n",
    "\n",
    "# Impute using median\n",
    "df_median_impute['LAND SQUARE FEET'] = df_median_impute['LAND SQUARE FEET'].fillna(df_median_impute['LAND SQUARE FEET'].median())\n",
    "df_median_impute['GROSS SQUARE FEET'] = df_median_impute['GROSS SQUARE FEET'].fillna(df_median_impute['GROSS SQUARE FEET'].median())\n",
    "df_median_impute = kmeans_remove_outliers(df_median_impute)\n",
    "\n",
    "# Impute using mean\n",
    "df_mean_inpute['LAND SQUARE FEET'] = df_mean_inpute['LAND SQUARE FEET'].fillna(df_mean_inpute['LAND SQUARE FEET'].mean())\n",
    "df_mean_inpute['GROSS SQUARE FEET'] = df_mean_inpute['GROSS SQUARE FEET'].fillna(df_mean_inpute['GROSS SQUARE FEET'].mean())\n",
    "df_mean_inpute = kmeans_remove_outliers(df_mean_inpute)\n",
    "\n",
    "# Impute using KNN\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_knn_impute['LAND SQUARE FEET'] = imputer.fit_transform(df_knn_impute[['LAND SQUARE FEET']])\n",
    "df_knn_impute['GROSS SQUARE FEET'] = imputer.fit_transform(df_knn_impute[['GROSS SQUARE FEET']])\n",
    "df_knn_impute = kmeans_remove_outliers(df_knn_impute)\n",
    "\n",
    "# Delete rows with missing values fir df_no_impute\n",
    "df_no_impute.dropna(inplace=True)\n",
    "df_no_impute = kmeans_remove_outliers(df_no_impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing missing values after cleanup\n",
    "# show_missing_values(df_median_impute)\n",
    "# show_missing_values(df_mean_inpute)\n",
    "# show_missing_values(df_knn_impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, title):\n",
    "    print(title)\n",
    "    print(cm)\n",
    "    # ax = plt.subplot()\n",
    "    # sns.heatmap(cm, annot=True, fmt=\"g\", ax=ax)\n",
    "    # # annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "    # # labels, title and ticks\n",
    "    # ax.set_xlabel(\"Predicted labels\")\n",
    "    # ax.set_ylabel(\"True labels\")\n",
    "    # ax.set_title(title)\n",
    "    # ax.xaxis.set_ticklabels(SALE_PRICE_LABELS)\n",
    "    # ax.yaxis.set_ticklabels(SALE_PRICE_LABELS)\n",
    "\n",
    "\n",
    "def get_predictions(model, X_train, X_test, y_train, y_test):\n",
    "    # Fit the model to the training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    return model.predict(X_test)\n",
    "\n",
    "# Return optimal k\n",
    "def get_optimal_k(dataframe):\n",
    "    # Get the feature and target columns\n",
    "    X = dataframe.drop(\"SALE PRICE\", axis=1)\n",
    "    y = dataframe[\"SALE PRICE\"]\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "    k_values = range(1, 21)\n",
    "    accuracy_map = dict()\n",
    "\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        target_pred = get_predictions(knn, X_train, X_test, y_train, y_test)\n",
    "        accuracy_map[k] = accuracy_score(y_test, target_pred) * 100\n",
    "\n",
    "    # Plot the accuracy for different values of k\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_values, accuracy_map.values())\n",
    "    plt.xticks(k_values)\n",
    "    plt.xlabel(\"Value of k\")\n",
    "    plt.ylabel(\"Testing Accuracy\")\n",
    "    plt.title(\"Accuracy for different values of k\")\n",
    "    plt.show()\n",
    "\n",
    "    # Get optimal k\n",
    "    optimal_k = max(accuracy_map, key=accuracy_map.get)\n",
    "    return optimal_k\n",
    "\n",
    "# Return model based on type passed\n",
    "def get_model(model_type, dataframe):\n",
    "    if model_type == \"gaussian_nb\":\n",
    "        return GaussianNB()\n",
    "    elif model_type == \"decision_tree\":\n",
    "        return DecisionTreeClassifier()\n",
    "    elif model_type == \"cart_5\":\n",
    "        return DecisionTreeClassifier(max_depth=5)\n",
    "    elif model_type == \"random_forest\":\n",
    "        return RandomForestClassifier()\n",
    "    elif model_type == \"svm\":\n",
    "        return SVC()\n",
    "    elif model_type == \"logistic_regression\":\n",
    "        return LogisticRegression()\n",
    "    elif model_type == \"knn\":\n",
    "        # Note for testing - Uncomment below code to get optimal k. It has been commented to avoid running it everytime.\n",
    "        # optimal_k = get_optimal_k(dataframe)\n",
    "        # Above function returns optimal k = 8\n",
    "        optimal_k = 8\n",
    "        print(\"The optimal number of neighbors is {}\".format(optimal_k))\n",
    "        return KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "    # elif model_type == \"xg_boost\":\n",
    "    #     return xgb.XGBClassifier()\n",
    "    # elif model_type == \"sequential_dense\":\n",
    "    #     return Sequential()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Write a common function to train and test the different models\n",
    "def train_and_test_model(model_type, dataframe):\n",
    "    # Get the model\n",
    "    model = get_model(model_type, dataframe)\n",
    "\n",
    "    # Get the feature and target columns\n",
    "    X = dataframe.drop(\"SALE PRICE\", axis=1)\n",
    "    y = dataframe[\"SALE PRICE\"]\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Get predictions\n",
    "    target_pred = get_predictions(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Get the confusion matrix\n",
    "    cm = confusion_matrix(y_test, target_pred)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plot_confusion_matrix(cm, \"Confusion Matrix for \" + model_type)\n",
    "\n",
    "    # Print the classification report\n",
    "    print(classification_report(y_test, target_pred))\n",
    "\n",
    "    # Print the accuracy\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, target_pred))\n",
    "\n",
    "def use_xg_boost_model(dataframe):\n",
    "    # Initialize the label encoder for the target variable\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Copy the dataframe to avoid modifying the original data\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    # Fit and transform the 'SALE PRICE' column\n",
    "    df[\"SALE PRICE\"] = label_encoder.fit_transform(df[\"SALE PRICE\"])\n",
    "\n",
    "    # Identify categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=[\"category\"]).columns\n",
    "\n",
    "    # Use pd.get_dummies() to create dummy variables for categorical columns\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = df.drop(\"SALE PRICE\", axis=1)\n",
    "    y = df[\"SALE PRICE\"]\n",
    "\n",
    "    # Splitting the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Create a XGBClassifier model\n",
    "    xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "    # Fit the model to the training set\n",
    "    xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "    # Generate and print the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(cm, \"Confusion Matrix for XGBClassifier\")\n",
    "\n",
    "    # Print the classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Print the accuracy\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "def use_sequential_dense_modal(dataframe):\n",
    "\n",
    "    # Get the feature and target columns\n",
    "    X = dataframe.drop(\"SALE PRICE\", axis=1)\n",
    "    y = dataframe[\"SALE PRICE\"]\n",
    "\n",
    "    # Convert the target column to categorical (one-hot encoding)\n",
    "    y_encoded = to_categorical(y.cat.codes)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y_encoded, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Get the number of input features\n",
    "    n_features = X_train.shape[1]\n",
    "\n",
    "    # Create a Sequential model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation=\"relu\", input_shape=(n_features,)))\n",
    "    model.add(Dense(100, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"softmax\"))  # Output layer for 4-class classification\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train, epochs=10, validation_split=0.3)\n",
    "\n",
    "    # Evaluating the Model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe:  Median Impute\n",
      "\n",
      "\n",
      "KNN\n",
      "The optimal number of neighbors is 8\n",
      "Confusion Matrix for knn\n",
      "[[2735  249  688  756]\n",
      " [ 407 2931  872  221]\n",
      " [ 951  939 2221  225]\n",
      " [1037   79  160 3149]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.53      0.62      0.57      4428\n",
      "         Low       0.70      0.66      0.68      4431\n",
      "      Medium       0.56      0.51      0.54      4336\n",
      "   Very High       0.72      0.71      0.72      4425\n",
      "\n",
      "    accuracy                           0.63     17620\n",
      "   macro avg       0.63      0.63      0.63     17620\n",
      "weighted avg       0.63      0.63      0.63     17620\n",
      "\n",
      "Accuracy: 0.62633371169126\n",
      "\n",
      "\n",
      "Gaussian NB\n",
      "Confusion Matrix for gaussian_nb\n",
      "[[1228   83 2963  154]\n",
      " [ 634   40 3572  185]\n",
      " [ 717   44 3483   92]\n",
      " [1877  184 1666  698]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.28      0.28      0.28      4428\n",
      "         Low       0.11      0.01      0.02      4431\n",
      "      Medium       0.30      0.80      0.43      4336\n",
      "   Very High       0.62      0.16      0.25      4425\n",
      "\n",
      "    accuracy                           0.31     17620\n",
      "   macro avg       0.33      0.31      0.24     17620\n",
      "weighted avg       0.33      0.31      0.24     17620\n",
      "\n",
      "Accuracy: 0.30925085130533486\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Confusion Matrix for decision_tree\n",
      "[[2499  379  801  749]\n",
      " [ 360 2966  917  188]\n",
      " [ 939 1096 2137  164]\n",
      " [ 946  212  189 3078]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.53      0.56      0.54      4428\n",
      "         Low       0.64      0.67      0.65      4431\n",
      "      Medium       0.53      0.49      0.51      4336\n",
      "   Very High       0.74      0.70      0.72      4425\n",
      "\n",
      "    accuracy                           0.61     17620\n",
      "   macro avg       0.61      0.61      0.61     17620\n",
      "weighted avg       0.61      0.61      0.61     17620\n",
      "\n",
      "Accuracy: 0.6061293984108967\n",
      "\n",
      "\n",
      "CART 5\n",
      "Confusion Matrix for cart_5\n",
      "[[2177  101  789 1361]\n",
      " [ 548 2237 1254  392]\n",
      " [1183  511 2092  550]\n",
      " [1017   64   60 3284]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.44      0.49      0.47      4428\n",
      "         Low       0.77      0.50      0.61      4431\n",
      "      Medium       0.50      0.48      0.49      4336\n",
      "   Very High       0.59      0.74      0.66      4425\n",
      "\n",
      "    accuracy                           0.56     17620\n",
      "   macro avg       0.57      0.56      0.56     17620\n",
      "weighted avg       0.57      0.56      0.56     17620\n",
      "\n",
      "Accuracy: 0.5556186152099887\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Confusion Matrix for random_forest\n",
      "[[2683  193  737  815]\n",
      " [ 329 2900  988  214]\n",
      " [ 776  788 2566  206]\n",
      " [ 796   70  123 3436]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.59      0.61      0.60      4428\n",
      "         Low       0.73      0.65      0.69      4431\n",
      "      Medium       0.58      0.59      0.59      4336\n",
      "   Very High       0.74      0.78      0.76      4425\n",
      "\n",
      "    accuracy                           0.66     17620\n",
      "   macro avg       0.66      0.66      0.66     17620\n",
      "weighted avg       0.66      0.66      0.66     17620\n",
      "\n",
      "Accuracy: 0.6574914869466515\n",
      "\n",
      "\n",
      "SVM\n",
      "Confusion Matrix for svm\n",
      "[[1758  496  496 1678]\n",
      " [1005 1344 1289  793]\n",
      " [ 882  561 1765 1128]\n",
      " [ 862   82   23 3458]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.39      0.40      0.39      4428\n",
      "         Low       0.54      0.30      0.39      4431\n",
      "      Medium       0.49      0.41      0.45      4336\n",
      "   Very High       0.49      0.78      0.60      4425\n",
      "\n",
      "    accuracy                           0.47     17620\n",
      "   macro avg       0.48      0.47      0.46     17620\n",
      "weighted avg       0.48      0.47      0.46     17620\n",
      "\n",
      "Accuracy: 0.4724744608399546\n",
      "\n",
      "\n",
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anirudhchintha/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for logistic_regression\n",
      "[[1178 1013  601 1636]\n",
      " [ 846 2067  502 1016]\n",
      " [ 677 1484  925 1250]\n",
      " [ 665  421  121 3218]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.35      0.27      0.30      4428\n",
      "         Low       0.41      0.47      0.44      4431\n",
      "      Medium       0.43      0.21      0.29      4336\n",
      "   Very High       0.45      0.73      0.56      4425\n",
      "\n",
      "    accuracy                           0.42     17620\n",
      "   macro avg       0.41      0.42      0.40     17620\n",
      "weighted avg       0.41      0.42      0.40     17620\n",
      "\n",
      "Accuracy: 0.41929625425652667\n",
      "\n",
      "\n",
      "XG Boost\n",
      "Confusion Matrix for XGBClassifier\n",
      "[[2692  120  704  912]\n",
      " [ 324 2912  935  260]\n",
      " [ 840  734 2505  257]\n",
      " [ 714   34   88 3589]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60      4428\n",
      "           1       0.77      0.66      0.71      4431\n",
      "           2       0.59      0.58      0.58      4336\n",
      "           3       0.72      0.81      0.76      4425\n",
      "\n",
      "    accuracy                           0.66     17620\n",
      "   macro avg       0.67      0.66      0.66     17620\n",
      "weighted avg       0.67      0.66      0.66     17620\n",
      "\n",
      "Accuracy: 0.6639046538024972\n",
      "\n",
      "\n",
      "Sequential Dense Model\n",
      "Epoch 1/10\n",
      "900/900 [==============================] - 1s 794us/step - loss: 1.0663 - accuracy: 0.5273 - val_loss: 1.0135 - val_accuracy: 0.5615\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.9842 - accuracy: 0.5693 - val_loss: 0.9832 - val_accuracy: 0.5684\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.9601 - accuracy: 0.5843 - val_loss: 0.9604 - val_accuracy: 0.5827\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 794us/step - loss: 0.9448 - accuracy: 0.5905 - val_loss: 0.9525 - val_accuracy: 0.5818\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.9327 - accuracy: 0.5953 - val_loss: 0.9463 - val_accuracy: 0.5816\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.9228 - accuracy: 0.6010 - val_loss: 0.9356 - val_accuracy: 0.5958\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.9159 - accuracy: 0.6045 - val_loss: 0.9273 - val_accuracy: 0.5947\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.9086 - accuracy: 0.6078 - val_loss: 0.9343 - val_accuracy: 0.5969\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 724us/step - loss: 0.9036 - accuracy: 0.6097 - val_loss: 0.9232 - val_accuracy: 0.6022\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 711us/step - loss: 0.8980 - accuracy: 0.6119 - val_loss: 0.9237 - val_accuracy: 0.5983\n",
      "551/551 [==============================] - 0s 354us/step - loss: 0.9200 - accuracy: 0.5931\n",
      "Accuracy: 0.5931327939033508\n",
      "\n",
      "\n",
      "\n",
      "Dataframe:  Mean Impute\n",
      "\n",
      "\n",
      "KNN\n",
      "The optimal number of neighbors is 8\n",
      "Confusion Matrix for knn\n",
      "[[2681  230  699  765]\n",
      " [ 431 2850  862  220]\n",
      " [ 971  913 2218  210]\n",
      " [1001   89  122 3183]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.53      0.61      0.57      4375\n",
      "         Low       0.70      0.65      0.67      4363\n",
      "      Medium       0.57      0.51      0.54      4312\n",
      "   Very High       0.73      0.72      0.73      4395\n",
      "\n",
      "    accuracy                           0.63     17445\n",
      "   macro avg       0.63      0.63      0.63     17445\n",
      "weighted avg       0.63      0.63      0.63     17445\n",
      "\n",
      "Accuracy: 0.6266552020636286\n",
      "\n",
      "\n",
      "Gaussian NB\n",
      "Confusion Matrix for gaussian_nb\n",
      "[[1164  206 2795  210]\n",
      " [ 537  393 3240  193]\n",
      " [ 738  197 3278   99]\n",
      " [1798  221 1495  881]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.27      0.27      0.27      4375\n",
      "         Low       0.39      0.09      0.15      4363\n",
      "      Medium       0.30      0.76      0.43      4312\n",
      "   Very High       0.64      0.20      0.30      4395\n",
      "\n",
      "    accuracy                           0.33     17445\n",
      "   macro avg       0.40      0.33      0.29     17445\n",
      "weighted avg       0.40      0.33      0.29     17445\n",
      "\n",
      "Accuracy: 0.32765835482946404\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Confusion Matrix for decision_tree\n",
      "[[2487  362  824  702]\n",
      " [ 390 2892  900  181]\n",
      " [ 907 1058 2170  177]\n",
      " [ 986  202  191 3016]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.52      0.57      0.54      4375\n",
      "         Low       0.64      0.66      0.65      4363\n",
      "      Medium       0.53      0.50      0.52      4312\n",
      "   Very High       0.74      0.69      0.71      4395\n",
      "\n",
      "    accuracy                           0.61     17445\n",
      "   macro avg       0.61      0.61      0.61     17445\n",
      "weighted avg       0.61      0.61      0.61     17445\n",
      "\n",
      "Accuracy: 0.6056176554886787\n",
      "\n",
      "\n",
      "CART 5\n",
      "Confusion Matrix for cart_5\n",
      "[[2015  108 1056 1196]\n",
      " [ 535 2221 1320  287]\n",
      " [1007  521 2277  507]\n",
      " [1101   29  131 3134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.43      0.46      0.45      4375\n",
      "         Low       0.77      0.51      0.61      4363\n",
      "      Medium       0.48      0.53      0.50      4312\n",
      "   Very High       0.61      0.71      0.66      4395\n",
      "\n",
      "    accuracy                           0.55     17445\n",
      "   macro avg       0.57      0.55      0.55     17445\n",
      "weighted avg       0.57      0.55      0.55     17445\n",
      "\n",
      "Accuracy: 0.5529951275437088\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Confusion Matrix for random_forest\n",
      "[[2647  188  752  788]\n",
      " [ 338 2876  966  183]\n",
      " [ 779  760 2554  219]\n",
      " [ 760   67  118 3450]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.59      0.61      0.59      4375\n",
      "         Low       0.74      0.66      0.70      4363\n",
      "      Medium       0.58      0.59      0.59      4312\n",
      "   Very High       0.74      0.78      0.76      4395\n",
      "\n",
      "    accuracy                           0.66     17445\n",
      "   macro avg       0.66      0.66      0.66     17445\n",
      "weighted avg       0.66      0.66      0.66     17445\n",
      "\n",
      "Accuracy: 0.660762396102035\n",
      "\n",
      "\n",
      "SVM\n",
      "Confusion Matrix for svm\n",
      "[[1649  523  680 1523]\n",
      " [ 466 2126 1146  625]\n",
      " [ 588  725 2053  946]\n",
      " [ 694  305   36 3360]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.49      0.38      0.42      4375\n",
      "         Low       0.58      0.49      0.53      4363\n",
      "      Medium       0.52      0.48      0.50      4312\n",
      "   Very High       0.52      0.76      0.62      4395\n",
      "\n",
      "    accuracy                           0.53     17445\n",
      "   macro avg       0.53      0.53      0.52     17445\n",
      "weighted avg       0.53      0.53      0.52     17445\n",
      "\n",
      "Accuracy: 0.5266838635712239\n",
      "\n",
      "\n",
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anirudhchintha/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for logistic_regression\n",
      "[[1457  948  625 1345]\n",
      " [ 764 1238 1528  833]\n",
      " [ 723  897 1683 1009]\n",
      " [ 838  538  110 2909]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.39      0.33      0.36      4375\n",
      "         Low       0.34      0.28      0.31      4363\n",
      "      Medium       0.43      0.39      0.41      4312\n",
      "   Very High       0.48      0.66      0.55      4395\n",
      "\n",
      "    accuracy                           0.42     17445\n",
      "   macro avg       0.41      0.42      0.41     17445\n",
      "weighted avg       0.41      0.42      0.41     17445\n",
      "\n",
      "Accuracy: 0.4177128116938951\n",
      "\n",
      "\n",
      "XG Boost\n",
      "Confusion Matrix for XGBClassifier\n",
      "[[2658  119  682  916]\n",
      " [ 345 2837  943  238]\n",
      " [ 795  682 2545  290]\n",
      " [ 688   34   63 3610]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60      4375\n",
      "           1       0.77      0.65      0.71      4363\n",
      "           2       0.60      0.59      0.60      4312\n",
      "           3       0.71      0.82      0.76      4395\n",
      "\n",
      "    accuracy                           0.67     17445\n",
      "   macro avg       0.67      0.67      0.67     17445\n",
      "weighted avg       0.67      0.67      0.67     17445\n",
      "\n",
      "Accuracy: 0.6678131269704787\n",
      "\n",
      "\n",
      "Sequential Dense Model\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 1s 799us/step - loss: 1.0634 - accuracy: 0.5288 - val_loss: 0.9939 - val_accuracy: 0.5634\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 1s 815us/step - loss: 0.9853 - accuracy: 0.5651 - val_loss: 0.9634 - val_accuracy: 0.5795\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 1s 818us/step - loss: 0.9615 - accuracy: 0.5759 - val_loss: 0.9513 - val_accuracy: 0.5856\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 1s 838us/step - loss: 0.9488 - accuracy: 0.5858 - val_loss: 0.9404 - val_accuracy: 0.5893\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 1s 949us/step - loss: 0.9372 - accuracy: 0.5913 - val_loss: 0.9281 - val_accuracy: 0.5920\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 1s 809us/step - loss: 0.9275 - accuracy: 0.5963 - val_loss: 0.9245 - val_accuracy: 0.6001\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 1s 743us/step - loss: 0.9201 - accuracy: 0.6003 - val_loss: 0.9181 - val_accuracy: 0.6039\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 1s 751us/step - loss: 0.9140 - accuracy: 0.6014 - val_loss: 0.9223 - val_accuracy: 0.5957\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 1s 809us/step - loss: 0.9063 - accuracy: 0.6067 - val_loss: 0.9187 - val_accuracy: 0.6041\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 1s 908us/step - loss: 0.9033 - accuracy: 0.6099 - val_loss: 0.9099 - val_accuracy: 0.6051\n",
      "546/546 [==============================] - 0s 503us/step - loss: 0.9241 - accuracy: 0.6096\n",
      "Accuracy: 0.609630286693573\n",
      "\n",
      "\n",
      "\n",
      "Dataframe:  KNN Impute\n",
      "\n",
      "\n",
      "KNN\n",
      "The optimal number of neighbors is 8\n",
      "Confusion Matrix for knn\n",
      "[[2681  230  699  765]\n",
      " [ 431 2850  862  220]\n",
      " [ 971  913 2218  210]\n",
      " [1001   89  122 3183]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.53      0.61      0.57      4375\n",
      "         Low       0.70      0.65      0.67      4363\n",
      "      Medium       0.57      0.51      0.54      4312\n",
      "   Very High       0.73      0.72      0.73      4395\n",
      "\n",
      "    accuracy                           0.63     17445\n",
      "   macro avg       0.63      0.63      0.63     17445\n",
      "weighted avg       0.63      0.63      0.63     17445\n",
      "\n",
      "Accuracy: 0.6266552020636286\n",
      "\n",
      "\n",
      "Gaussian NB\n",
      "Confusion Matrix for gaussian_nb\n",
      "[[1164  206 2795  210]\n",
      " [ 537  393 3240  193]\n",
      " [ 738  197 3278   99]\n",
      " [1798  221 1495  881]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.27      0.27      0.27      4375\n",
      "         Low       0.39      0.09      0.15      4363\n",
      "      Medium       0.30      0.76      0.43      4312\n",
      "   Very High       0.64      0.20      0.30      4395\n",
      "\n",
      "    accuracy                           0.33     17445\n",
      "   macro avg       0.40      0.33      0.29     17445\n",
      "weighted avg       0.40      0.33      0.29     17445\n",
      "\n",
      "Accuracy: 0.32765835482946404\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Confusion Matrix for decision_tree\n",
      "[[2478  364  831  702]\n",
      " [ 372 2923  890  178]\n",
      " [ 906 1056 2166  184]\n",
      " [ 979  202  187 3027]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.52      0.57      0.54      4375\n",
      "         Low       0.64      0.67      0.66      4363\n",
      "      Medium       0.53      0.50      0.52      4312\n",
      "   Very High       0.74      0.69      0.71      4395\n",
      "\n",
      "    accuracy                           0.61     17445\n",
      "   macro avg       0.61      0.61      0.61     17445\n",
      "weighted avg       0.61      0.61      0.61     17445\n",
      "\n",
      "Accuracy: 0.6072800229292061\n",
      "\n",
      "\n",
      "CART 5\n",
      "Confusion Matrix for cart_5\n",
      "[[2015  108 1056 1196]\n",
      " [ 535 2221 1320  287]\n",
      " [1007  521 2277  507]\n",
      " [1101   29  131 3134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.43      0.46      0.45      4375\n",
      "         Low       0.77      0.51      0.61      4363\n",
      "      Medium       0.48      0.53      0.50      4312\n",
      "   Very High       0.61      0.71      0.66      4395\n",
      "\n",
      "    accuracy                           0.55     17445\n",
      "   macro avg       0.57      0.55      0.55     17445\n",
      "weighted avg       0.57      0.55      0.55     17445\n",
      "\n",
      "Accuracy: 0.5529951275437088\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Confusion Matrix for random_forest\n",
      "[[2635  187  766  787]\n",
      " [ 329 2869  976  189]\n",
      " [ 784  792 2537  199]\n",
      " [ 761   67  115 3452]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.58      0.60      0.59      4375\n",
      "         Low       0.73      0.66      0.69      4363\n",
      "      Medium       0.58      0.59      0.58      4312\n",
      "   Very High       0.75      0.79      0.77      4395\n",
      "\n",
      "    accuracy                           0.66     17445\n",
      "   macro avg       0.66      0.66      0.66     17445\n",
      "weighted avg       0.66      0.66      0.66     17445\n",
      "\n",
      "Accuracy: 0.6588134135855546\n",
      "\n",
      "\n",
      "SVM\n",
      "Confusion Matrix for svm\n",
      "[[1649  523  680 1523]\n",
      " [ 466 2126 1146  625]\n",
      " [ 588  725 2053  946]\n",
      " [ 694  305   36 3360]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.49      0.38      0.42      4375\n",
      "         Low       0.58      0.49      0.53      4363\n",
      "      Medium       0.52      0.48      0.50      4312\n",
      "   Very High       0.52      0.76      0.62      4395\n",
      "\n",
      "    accuracy                           0.53     17445\n",
      "   macro avg       0.53      0.53      0.52     17445\n",
      "weighted avg       0.53      0.53      0.52     17445\n",
      "\n",
      "Accuracy: 0.5266838635712239\n",
      "\n",
      "\n",
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anirudhchintha/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for logistic_regression\n",
      "[[1457  948  625 1345]\n",
      " [ 764 1238 1528  833]\n",
      " [ 723  897 1683 1009]\n",
      " [ 838  538  110 2909]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.39      0.33      0.36      4375\n",
      "         Low       0.34      0.28      0.31      4363\n",
      "      Medium       0.43      0.39      0.41      4312\n",
      "   Very High       0.48      0.66      0.55      4395\n",
      "\n",
      "    accuracy                           0.42     17445\n",
      "   macro avg       0.41      0.42      0.41     17445\n",
      "weighted avg       0.41      0.42      0.41     17445\n",
      "\n",
      "Accuracy: 0.4177128116938951\n",
      "\n",
      "\n",
      "XG Boost\n",
      "Confusion Matrix for XGBClassifier\n",
      "[[2658  119  682  916]\n",
      " [ 345 2837  943  238]\n",
      " [ 795  682 2545  290]\n",
      " [ 688   34   63 3610]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60      4375\n",
      "           1       0.77      0.65      0.71      4363\n",
      "           2       0.60      0.59      0.60      4312\n",
      "           3       0.71      0.82      0.76      4395\n",
      "\n",
      "    accuracy                           0.67     17445\n",
      "   macro avg       0.67      0.67      0.67     17445\n",
      "weighted avg       0.67      0.67      0.67     17445\n",
      "\n",
      "Accuracy: 0.6678131269704787\n",
      "\n",
      "\n",
      "Sequential Dense Model\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 1s 950us/step - loss: 1.0665 - accuracy: 0.5274 - val_loss: 0.9971 - val_accuracy: 0.5636\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 1s 765us/step - loss: 0.9879 - accuracy: 0.5671 - val_loss: 0.9627 - val_accuracy: 0.5802\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 1s 770us/step - loss: 0.9627 - accuracy: 0.5764 - val_loss: 0.9568 - val_accuracy: 0.5802\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 1s 744us/step - loss: 0.9476 - accuracy: 0.5870 - val_loss: 0.9383 - val_accuracy: 0.5919\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 1s 768us/step - loss: 0.9354 - accuracy: 0.5940 - val_loss: 0.9295 - val_accuracy: 0.5974\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 1s 750us/step - loss: 0.9257 - accuracy: 0.5982 - val_loss: 0.9263 - val_accuracy: 0.5978\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 1s 755us/step - loss: 0.9190 - accuracy: 0.6013 - val_loss: 0.9157 - val_accuracy: 0.6057\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 1s 740us/step - loss: 0.9121 - accuracy: 0.6037 - val_loss: 0.9137 - val_accuracy: 0.6027\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 1s 750us/step - loss: 0.9048 - accuracy: 0.6062 - val_loss: 0.9226 - val_accuracy: 0.5998\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 1s 744us/step - loss: 0.9008 - accuracy: 0.6076 - val_loss: 0.9090 - val_accuracy: 0.6055\n",
      "546/546 [==============================] - 0s 371us/step - loss: 0.9176 - accuracy: 0.6092\n",
      "Accuracy: 0.6091716885566711\n",
      "\n",
      "\n",
      "\n",
      "Dataframe:  No Impute\n",
      "\n",
      "\n",
      "KNN\n",
      "The optimal number of neighbors is 8\n",
      "Confusion Matrix for knn\n",
      "[[1715  192  480  475]\n",
      " [ 376 1609  639  224]\n",
      " [ 683  706 1240  107]\n",
      " [ 558   59   41 2168]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.51      0.60      0.55      2862\n",
      "         Low       0.63      0.56      0.59      2848\n",
      "      Medium       0.52      0.45      0.48      2736\n",
      "   Very High       0.73      0.77      0.75      2826\n",
      "\n",
      "    accuracy                           0.60     11272\n",
      "   macro avg       0.60      0.60      0.59     11272\n",
      "weighted avg       0.60      0.60      0.60     11272\n",
      "\n",
      "Accuracy: 0.5972320794889993\n",
      "\n",
      "\n",
      "Gaussian NB\n",
      "Confusion Matrix for gaussian_nb\n",
      "[[2639    0   18  205]\n",
      " [2567    4   41  236]\n",
      " [2611    1    3  121]\n",
      " [1893   16  129  788]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.27      0.92      0.42      2862\n",
      "         Low       0.19      0.00      0.00      2848\n",
      "      Medium       0.02      0.00      0.00      2736\n",
      "   Very High       0.58      0.28      0.38      2826\n",
      "\n",
      "    accuracy                           0.30     11272\n",
      "   macro avg       0.27      0.30      0.20     11272\n",
      "weighted avg       0.27      0.30      0.20     11272\n",
      "\n",
      "Accuracy: 0.30464868701206527\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Confusion Matrix for decision_tree\n",
      "[[1506  351  548  457]\n",
      " [ 322 1671  695  160]\n",
      " [ 546  796 1285  109]\n",
      " [ 556  203  136 1931]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.51      0.53      0.52      2862\n",
      "         Low       0.55      0.59      0.57      2848\n",
      "      Medium       0.48      0.47      0.48      2736\n",
      "   Very High       0.73      0.68      0.70      2826\n",
      "\n",
      "    accuracy                           0.57     11272\n",
      "   macro avg       0.57      0.57      0.57     11272\n",
      "weighted avg       0.57      0.57      0.57     11272\n",
      "\n",
      "Accuracy: 0.5671575585521647\n",
      "\n",
      "\n",
      "CART 5\n",
      "Confusion Matrix for cart_5\n",
      "[[1924   59  529  350]\n",
      " [ 543 1075 1012  218]\n",
      " [ 837  233 1552  114]\n",
      " [ 997   28   47 1754]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.45      0.67      0.54      2862\n",
      "         Low       0.77      0.38      0.51      2848\n",
      "      Medium       0.49      0.57      0.53      2736\n",
      "   Very High       0.72      0.62      0.67      2826\n",
      "\n",
      "    accuracy                           0.56     11272\n",
      "   macro avg       0.61      0.56      0.56     11272\n",
      "weighted avg       0.61      0.56      0.56     11272\n",
      "\n",
      "Accuracy: 0.5593506032647267\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Confusion Matrix for random_forest\n",
      "[[1712  196  493  461]\n",
      " [ 311 1643  716  178]\n",
      " [ 519  607 1501  109]\n",
      " [ 435   46   50 2295]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.58      0.60      0.59      2862\n",
      "         Low       0.66      0.58      0.62      2848\n",
      "      Medium       0.54      0.55      0.55      2736\n",
      "   Very High       0.75      0.81      0.78      2826\n",
      "\n",
      "    accuracy                           0.63     11272\n",
      "   macro avg       0.63      0.63      0.63     11272\n",
      "weighted avg       0.63      0.63      0.63     11272\n",
      "\n",
      "Accuracy: 0.634403832505323\n",
      "\n",
      "\n",
      "SVM\n",
      "Confusion Matrix for svm\n",
      "[[1043  182  755  882]\n",
      " [ 439 1074  933  402]\n",
      " [ 584  289 1440  423]\n",
      " [ 786   83   69 1888]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.37      0.36      0.37      2862\n",
      "         Low       0.66      0.38      0.48      2848\n",
      "      Medium       0.45      0.53      0.49      2736\n",
      "   Very High       0.53      0.67      0.59      2826\n",
      "\n",
      "    accuracy                           0.48     11272\n",
      "   macro avg       0.50      0.48      0.48     11272\n",
      "weighted avg       0.50      0.48      0.48     11272\n",
      "\n",
      "Accuracy: 0.48305535841022\n",
      "\n",
      "\n",
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anirudhchintha/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for logistic_regression\n",
      "[[ 649  528  737  948]\n",
      " [ 243 1460  616  529]\n",
      " [ 285  839 1079  533]\n",
      " [ 489  281  298 1758]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.39      0.23      0.29      2862\n",
      "         Low       0.47      0.51      0.49      2848\n",
      "      Medium       0.40      0.39      0.39      2736\n",
      "   Very High       0.47      0.62      0.53      2826\n",
      "\n",
      "    accuracy                           0.44     11272\n",
      "   macro avg       0.43      0.44      0.43     11272\n",
      "weighted avg       0.43      0.44      0.43     11272\n",
      "\n",
      "Accuracy: 0.4387863733144074\n",
      "\n",
      "\n",
      "XG Boost\n",
      "Confusion Matrix for XGBClassifier\n",
      "[[1787  129  486  460]\n",
      " [ 304 1647  699  198]\n",
      " [ 520  576 1522  118]\n",
      " [ 424   28   23 2351]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.61      2862\n",
      "           1       0.69      0.58      0.63      2848\n",
      "           2       0.56      0.56      0.56      2736\n",
      "           3       0.75      0.83      0.79      2826\n",
      "\n",
      "    accuracy                           0.65     11272\n",
      "   macro avg       0.65      0.65      0.65     11272\n",
      "weighted avg       0.65      0.65      0.65     11272\n",
      "\n",
      "Accuracy: 0.6482434350603264\n",
      "\n",
      "\n",
      "Sequential Dense Model\n",
      "Epoch 1/10\n",
      "576/576 [==============================] - 1s 813us/step - loss: 1.1710 - accuracy: 0.4763 - val_loss: 1.1078 - val_accuracy: 0.5240\n",
      "Epoch 2/10\n",
      "576/576 [==============================] - 0s 727us/step - loss: 1.0908 - accuracy: 0.5281 - val_loss: 1.0530 - val_accuracy: 0.5529\n",
      "Epoch 3/10\n",
      "576/576 [==============================] - 0s 728us/step - loss: 1.0310 - accuracy: 0.5509 - val_loss: 1.0404 - val_accuracy: 0.5632\n",
      "Epoch 4/10\n",
      "576/576 [==============================] - 0s 727us/step - loss: 0.9952 - accuracy: 0.5650 - val_loss: 1.0022 - val_accuracy: 0.5677\n",
      "Epoch 5/10\n",
      "576/576 [==============================] - 0s 803us/step - loss: 0.9722 - accuracy: 0.5750 - val_loss: 0.9915 - val_accuracy: 0.5735\n",
      "Epoch 6/10\n",
      "576/576 [==============================] - 0s 725us/step - loss: 0.9575 - accuracy: 0.5870 - val_loss: 0.9855 - val_accuracy: 0.5773\n",
      "Epoch 7/10\n",
      "576/576 [==============================] - 0s 725us/step - loss: 0.9473 - accuracy: 0.5906 - val_loss: 0.9669 - val_accuracy: 0.5886\n",
      "Epoch 8/10\n",
      "576/576 [==============================] - 0s 723us/step - loss: 0.9378 - accuracy: 0.5973 - val_loss: 0.9689 - val_accuracy: 0.5805\n",
      "Epoch 9/10\n",
      "576/576 [==============================] - 0s 732us/step - loss: 0.9305 - accuracy: 0.5943 - val_loss: 0.9620 - val_accuracy: 0.5897\n",
      "Epoch 10/10\n",
      "576/576 [==============================] - 0s 724us/step - loss: 0.9220 - accuracy: 0.6001 - val_loss: 0.9485 - val_accuracy: 0.5915\n",
      "353/353 [==============================] - 0s 364us/step - loss: 0.9273 - accuracy: 0.5937\n",
      "Accuracy: 0.5936834812164307\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_map = {\n",
    "    \"Median Impute\": df_median_impute,\n",
    "    \"Mean Impute\": df_mean_inpute,\n",
    "    \"KNN Impute\": df_knn_impute,\n",
    "    \"No Impute\": df_no_impute,\n",
    "}\n",
    "\n",
    "for df_key in df_map.keys():\n",
    "    # Get df_name from key\n",
    "    print(\"Dataframe: \", df_key)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    df_item = df_map[df_key]\n",
    "\n",
    "    print(\"KNN\")\n",
    "    train_and_test_model(\"knn\", df_item)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Gaussian NB\")\n",
    "    train_and_test_model(\"gaussian_nb\", df_item)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Decision Tree\")\n",
    "    train_and_test_model(\"decision_tree\", df_item)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"CART 5\")\n",
    "    train_and_test_model(\"cart_5\", df_item)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Random Forest\")\n",
    "    train_and_test_model(\"random_forest\", df_item)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"SVM\")\n",
    "    train_and_test_model(\"svm\", df_item)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    print(\"Logistic Regression\")\n",
    "    train_and_test_model(\"logistic_regression\", df_item)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"XG Boost\")\n",
    "    use_xg_boost_model(df_item)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Sequential Dense Model\")\n",
    "    use_sequential_dense_modal(df_item)\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
